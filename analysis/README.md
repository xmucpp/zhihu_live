# zhihu_live
data cleaning and easy visualization

## function of files
- data: 数据清洗
- analysis：数据可视化
- live_ednde:来源数据（已结束的知乎Live）
- ended:清洗后数据
- des_end:数据描述
- live_ongoing：来源数据（正在进行的Live）
- ongoing:清洗后数据
- des_ongo:数据描述
- all:合并数据
- result_zhihu_live.ipynb：Jupyter notebook输出的结果描述
## 处理过程
### 数据清洗
- 异常值：将0值改为nan
- 将费用中的数字提取出来
- 提取了介绍的字数（可能与关注人数有关）

### 数据可视化
- 直方图
- 箱形图
- 简单线性回归分析
 
## 新的尝试
- 这次把所有的代码写成函数，可以直接通过表格名称调用
    
    - 有空的时候写成包，以后不用再复制代码了，别人可视化的时候应该也可以用
- 基本用sns画图，感觉挺好用的
    
    - btw,pycharm画图比Spyder友好（也可能因为我改进了代码.尴尬）

## 下一步工作
- 学习可视化之后的后期处理怎么做

## 疑问及备注
- 想打标签，需要get到列名…这个不会
- 关于编码：开头的import sys...一串代码的改进方案是？
- 可视化和统计分析数据太多了反而不知道怎么选择和使用
- btw..特意筛出了介绍字数，从这个数据的表现来看可以说几乎和live的各项指标毫无关系，至于是和介绍内容无关还是仅仅和字数这个指标无关，如果要研究的话可以做进一步的文本分析（如表达特征、话题）（挖个坑等有空了回头试试）

-----


## 修改
1. 数据清洗：模块化
2. 数据分析：模块化
